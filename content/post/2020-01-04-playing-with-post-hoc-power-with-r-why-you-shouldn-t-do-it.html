---
title: 'Playing with post-hoc power with R - why we shouldn’t do it'
author: 'A. Baluja'
date: '2020-01-04'
slug: playing-with-post-hoc-power
categories:
  - R
tags:
  - '#rstats'
  - Statistical
  - research
  - '#tutorial'
  - medicine
  - power
keywords:
  - tech
thumbnailImagePosition: left
thumbnailImage: ./images/posthoc.png
metaAlignment: center
disable_comments: false
output:
  blogdown::html_page:
    toc: false
    fig_width: 8
    css: "/css/my-style.css"
editor_options: 
  chunk_output_type: console
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
  <link rel="stylesheet" href="/css/my-style.css" type="text/css" />


<p><em>(A half-baked post that I had some time ago pending finishing)</em></p>
<div id="current-state-of-the-matter" class="section level2">
<h2>Current state of the matter</h2>
<p>The reason for bringing this here is that I witnessed an interesting exchange some time ago, regarding one article and their use of post-hoc power, pinpointed by @<a href="https://twitter.com/ADAlthousePhD" target="_blank">ADAlthousePhD</a>:</p>
<center>
{{< tweet 1123205494968074240 >}}<br />
{{< tweet 1123206831885692928 >}} {{< tweet 1123575393481629697 >}}
</center>
<p>Tweets refer also to this great post: <strong><a href="http://daniellakens.blogspot.com/2014/12/observed-power-and-what-to-do-if-your.html" target="_blank">Observed power, and what to do if your editor asks for post-hoc power analyses</a></strong>, written by <a href="https://twitter.com/lakens" target="_blank">Daniël Lakens</a> in which this issue is discussed.</p>
<p>At first, I wasn’t too interested in this topic (to be honest)<!-- from an statistical point of view-->; but then I read <a href="https://www.sciencedirect.com/science/article/pii/S0022480419301854?via%3Dihub" target="_blank">the above mentioned study</a>, showcasing post-hoc calculations, and a few others that were <strong>spreading <em>and</em> being cited (even worse)</strong> in a field very, very close to mine: <strong>surgery</strong>. That’s when it got personal.</p>
<p>Like almost a year ago, I came across this beautiful paper: <strong><a href="https://www.vims.edu/people/hoenig_jm/pubs/hoenig2.pdf" target="_blank">The Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis</a></strong> by <a href="https://www.researchgate.net/profile/John_Hoenig" target="_blank">John Hoenig et al.</a></p>
<p>This paper patiently explains why post-hoc power is bad. Interestingly, the manuscript aims to be understood by scientists of all backgrounds, not only statistical. It uses appealing examples and develops them in a didactic, orderly manner, so a clinician (like myself) can grasp those concepts.</p>
<p><em>Also, the second paragraph begins using the word “Dismayingly”. How graphic.</em></p>
</div>
<div id="what-can-we-do-about-it" class="section level2">
<h2>What can we do about it?</h2>
<p>My two cents to this discussion abut <strong>post-hoc power</strong> come below in the form of a small R tutorial. It demonstrates, using the rationale in the paper, how it <em>doesn’t make sense</em> to get power calculations after hypothesis testing.</p>
<p>I hope this can help those peeps that need a more ‘<em>hands-on</em>’ (rather than purely abstract) approach to learning stats! R serves as a great, flexible tool for this!.</p>
<div id="observed-power-is-a-function-of-the-p-value" class="section level3">
<h3>Observed power is a function of the p-value</h3>
<p><em>(One determines the other)</em> <!--*(they're the same thing)*--></p>
<div class="well alert alert-info text-center">
<p>TL;DR: nonsignificant p values always correspond to low observed powers.</p>
</div>
<p>This piece of code is inspired by the one written by Lakens, only that it is done with p-values from a Chi-Square test, making use of the <code>pwr::pwr.chisq.test()</code> function to get the power of the study. The only problem is that the effect size in this function is given by <code>w</code>, but fortunately <em>w</em> can be estimated from our contingency table using this formula (from Cohen’s <a href="https://www.amazon.com/Statistical-Power-Analysis-Behavioral-Sciences/dp/0805802835" target="blank">book</a>, p.216):</p>
<p><span class="math inline">\(w = \sqrt{ \sum_{i=1}^{m} \dfrac{ (P_{1i} - P_{0i})^2 } {P_{0i}} }\)</span></p>
<ul>
<li><span class="math inline">\(P_{0i}\)</span> = the proportion in cell i posited by the null hypothesis,</li>
<li><span class="math inline">\(P_{1i}\)</span> = the proportion in cell i posited by the alternate hypothesis and reflects the effect for that cell, and</li>
<li><span class="math inline">\(m\)</span> = the number of cells.</li>
</ul>
<p>The reason I say “estimate” instead of to “calculate” the range of <em>w</em> values, is that we will use the sample proportions (observed, expected) instead of the population values (which we don’t know). Regardless effect size estimation in this case the results would be the same, so for didactic purposes this should be fine.</p>
<div id="defining-the-problem-genomic-data" class="section level4">
<h4>Defining the problem: genomic data</h4>
<p>Let’s start with a simplified case for the simplest possible contingency table: a 2x2 table featuring an exposure and the affected status in a <strong>case-control study</strong>:</p>
<ul>
<li>The Antithrombin-III-Hamilton disease is characterized by recurrent thromboembolic events (PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/3179438" target="blank">3179438</a>).</li>
<li>Caused by a DNA mutation exchanging Guanine (G) for Adenine (A) in the first base of codon 382 from the AT-III gene. This impairs its serine protease reactivity, thus being less effective blocking thrombus formation.</li>
<li>Thus, we can consider the “A” allele as the exposure, “G” as the absence of exposure, and the “cases” would be those with recurrent thromboembolic events.</li>
</ul>
<p>We cannot simulate from a <code>rnorm</code> distribution like in t-tests. To simulate datasets with different table proportions we will set a range of different frequency combinations for two of the cells:</p>
<pre class="r"><code>library(tidyverse)
# Set basic parameters
lower_prob_range=0.3
upper_prob_range=0.7
prob_step=0.01
probabilities &lt;- seq(from = lower_prob_range, to = upper_prob_range, by = prob_step)

# Create dataframe with all the possible effect sizes
mydata0 &lt;- expand.grid(probabilities,probabilities) %&gt;%
   tibble::as_tibble() %&gt;%
   rename(
      `prob of exposure in cases` = Var1,
      `prob of exposure in controls` = Var2
   )</code></pre>
<p>Next, we define a function that does all the calculations and stores the results in a list (the code is as inelegant and explicit as possible):</p>
<pre class="r"><code>power_against_pvalue &lt;- function(probabilities_expo_case=0.5, probabilities_expo_control=0.5, N=1000, exposure=&quot;exposed&quot;, unexposed=&quot;unexposed&quot;){
   require(pwr)
   require(magrittr)

   table_exposure &lt;- c(exposure, unexposed)
   
   # Make a data frame
   cases &lt;- tibble(
      status = &quot;case&quot;,
      allele = sample( table_exposure, N, replace=TRUE, prob=c(probabilities_expo_case, 1-probabilities_expo_case) )
   )
   controls &lt;- tibble(
      status = &quot;control&quot;,
      allele = sample( table_exposure, N, replace=TRUE, prob=c(probabilities_expo_control, 1-probabilities_expo_control) )
   )
   study &lt;- cases %&gt;%
      bind_rows(controls)
   
   # Observed counts
   .TableOC &lt;- table(study$status, study$allele)
   # Observed proportions (row)
   .TableOPr &lt;- prop.table(.TableOC, 1) # proportions by row
   # Observed proportions (table)
   .TableOP &lt;- prop.table(.TableOC) # proportions by table
   # Chi-squared test
   xsq_text &lt;- .TableOC %&gt;% chisq.test()
   # Expected table counts:
   .TableEC &lt;- xsq_text$expected   
   # Expected table proportions:
   .TableEP &lt;- prop.table(.TableEC) # proportions by table
   # get p-value
   xsq_pvalue &lt;- xsq_text$p.value
   
   # Observed counts:
   H_n &lt;- count_observed_ctrls_unexpo &lt;- .TableOC[2,2]
   D_n &lt;- count_observed_cases_unexpo &lt;- .TableOC[1,2]
   H_e &lt;- count_observed_ctrls_expo &lt;- .TableOC[2,1] # A is the exposure
   D_e &lt;- count_observed_cases_expo &lt;- .TableOC[1,1] # A is the exposure
   
   # Get the OR
   OR &lt;- ( D_e / H_e ) / ( D_n / H_n )
   
   # Observed table proportions
   pr_observed_ctrls_unexpo &lt;- .TableOP[2,2]
   pr_observed_case_unexpo &lt;- .TableOP[1,2]
   pr_observed_ctrls_expo &lt;- .TableOP[2,1]
   pr_observed_case_expo &lt;- .TableOP[1,1]
   
   # Expected table proportions:
   pr_expected_ctrls_unexpo &lt;- .TableEP[2,2]
   pr_expected_case_unexpo &lt;- .TableEP[1,2]
   pr_expected_ctrls_expo &lt;- .TableEP[2,1]
   pr_expected_case_expo &lt;- .TableEP[1,1]
   
   # Cohen&#39;s w
   w &lt;- (
      (
         (pr_expected_ctrls_unexpo - pr_observed_ctrls_unexpo)^2 / pr_expected_ctrls_unexpo
      ) + (
         (pr_expected_ctrls_expo - pr_observed_ctrls_expo)^2 / pr_expected_ctrls_expo
      ) + (
         (pr_expected_case_unexpo - pr_observed_case_unexpo)^2 / pr_expected_case_unexpo
      ) + (
         (pr_expected_case_expo - pr_observed_case_expo)^2 / pr_expected_case_expo
      )
   )^(1/2)
   
   # Power
   pw &lt;- pwr.chisq.test(
      w = w, 
      N = N, 
      df = 1, 
      sig.level = 0.05, 
      power = NULL
   )
   
   # Final result
   result0 &lt;- list(
      prob_case_in_exposed = probabilities_expo_case,
      prob_control_in_exposed = probabilities_expo_control,
      N = N,
      w = w,
      power = pw$power,
      p_value = xsq_pvalue,
      OR = OR,
      observed_counts = .TableOC,
      expected_counts = .TableEC,
      observed_proportions = .TableOP,
      expected_proportions = .TableEP
   )
   result0
   
}

# A helper function to extract the results into new columns
power_against_pvalue_extractor &lt;- function(power_versus_pvalue, extracted=NULL){
   if(is.null(extracted)){
      result &lt;- power_versus_pvalue
   }else{
      result &lt;- power_versus_pvalue[[extracted]]
   }
   result
}</code></pre>
<p>We can execute this function and see the output:</p>
<pre class="r"><code>power_against_pvalue(
   probabilities_expo_case=0.5, 
   probabilities_expo_control=0.5,
   N=1000, 
   exposure=&quot;A=exposed&quot;, 
   unexposed=&quot;G=unexposed&quot; 
)
   $prob_case_in_exposed
   [1] 0.5
   
   $prob_control_in_exposed
   [1] 0.5
   
   $N
   [1] 1000
   
   $w
   [1] 0.02300609
   
   $power
   [1] 0.1124906
   
   $p_value
   [1] 0.3250515
   
   $OR
   [1] 1.096436
   
   $observed_counts
            
             A=exposed G=unexposed
     case          523         477
     control       500         500
   
   $expected_counts
            
             A=exposed G=unexposed
     case        511.5       488.5
     control     511.5       488.5
   
   $observed_proportions
            
             A=exposed G=unexposed
     case       0.2615      0.2385
     control    0.2500      0.2500
   
   $expected_proportions
            
             A=exposed G=unexposed
     case      0.25575     0.24425
     control   0.25575     0.24425</code></pre>
<p>And now we can map this function to all the combinations of proportions we had stored in our data frame (using the wonderful <code>purrr</code> package):</p>
<pre class="r"><code>mydata &lt;- mydata0 %&gt;%
   # calculate
   mutate(
      power_versus_pvalue = purrr::map2(
         `prob of exposure in cases`, `prob of exposure in controls`, 
         ~power_against_pvalue(.x, .y, N=1000, exposure=&quot;A=exposed&quot;, unexposed=&quot;G=unexposed&quot;)
         )
   ) %&gt;%
   # extract elements
   mutate(
      power = purrr::map(power_versus_pvalue, power_against_pvalue_extractor, extracted=&quot;power&quot;),
      pvalue = purrr::map(power_versus_pvalue, power_against_pvalue_extractor, extracted=&quot;p_value&quot;),
      OR = purrr::map(power_versus_pvalue, power_against_pvalue_extractor, extracted=&quot;OR&quot;),
      cohen_w = purrr::map(power_versus_pvalue, power_against_pvalue_extractor, extracted=&quot;w&quot;)
   ) %&gt;%
   unnest(cols = c(power, pvalue, OR, cohen_w))</code></pre>
<pre class="r"><code>mydata %&gt;% select(-power_versus_pvalue, -cohen_w) %&gt;% head(3) %&gt;% kable()</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
prob of exposure in cases
</th>
<th style="text-align:center;">
prob of exposure in controls
</th>
<th style="text-align:center;">
power
</th>
<th style="text-align:center;">
pvalue
</th>
<th style="text-align:center;">
OR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.3
</td>
<td style="text-align:center;">
0.0500000
</td>
<td style="text-align:center;">
1.0000000
</td>
<td style="text-align:center;">
1.000000
</td>
</tr>
<tr>
<td style="text-align:center;">
0.31
</td>
<td style="text-align:center;">
0.3
</td>
<td style="text-align:center;">
0.1439164
</td>
<td style="text-align:center;">
0.2275967
</td>
<td style="text-align:center;">
1.128824
</td>
</tr>
<tr>
<td style="text-align:center;">
0.32
</td>
<td style="text-align:center;">
0.3
</td>
<td style="text-align:center;">
0.1547361
</td>
<td style="text-align:center;">
0.2025910
</td>
<td style="text-align:center;">
1.138560
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>We can see the power that corresponds to a p-value of 0.05:</p>
<pre class="r"><code>mydata %&gt;%
   filter(
      pvalue &gt; 0.049 &amp; pvalue &lt; 0.051
   ) %&gt;%
   select(-power_versus_pvalue, -cohen_w) %&gt;% kable()</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
prob of exposure in cases
</th>
<th style="text-align:center;">
prob of exposure in controls
</th>
<th style="text-align:center;">
power
</th>
<th style="text-align:center;">
pvalue
</th>
<th style="text-align:center;">
OR
</th>
</tr>
</thead>
<tbody>
<tr>
</tr>
</tbody>
</table>
<p> </p>
<p>The power corresponding to a p-value of 0.05 is between 0.29 and 0.30 (exact results will vary each time code runs; for didactic purposes I won’t <code>set.seed</code> here).</p>
<p>We can see how plotting power against p-value (regardless of sample size, you can try with a different one) always yield the same relationship:</p>
<pre class="r"><code>power_vs_pvalue &lt;- mydata %&gt;%
   ggplot(
      aes(
         x=power,
         y=pvalue,
         colour=pvalue
      )
   ) +
   geom_point() + 
   geom_hline(yintercept=0.05) + geom_vline(xintercept=0.29) +
   scale_colour_gradientn(colours = terrain.colors(5)) +
   theme_bw() + theme(legend.position = &quot;none&quot;)

power_vs_pvalue</code></pre>
<p><img src="/post/2020-01-04-playing-with-post-hoc-power-with-r-why-you-shouldn-t-do-it_files/figure-html/plot_output-1.png" width="480" />  </p>
</div>
</div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Once you set your data and statistical test to compute a p-value, your power is already fixed. Hence, power doesn’t add information and cannot be further interpreted, as higher p-values will <strong><em>always</em></strong> correspond to low powers.</p>
<p><a href="https://www.vims.edu/people/hoenig_jm/pubs/hoenig2.pdf" target="_blank">Hoenig’s paper</a> elaborates on more reasons why calculated (post-hoc) power cannot be interpreted (hence used). The Discussion section definitely worths reading.</p>
</div>
<div id="bonus" class="section level2">
<h2>Bonus</h2>
<div id="plotting-power-p-pvalue-against-or-and-cohens-w" class="section level4">
<h4>Plotting power &amp; p-pvalue against OR and Cohen’s <em>w</em></h4>
<p>Here are 4 graphs corresponding to 1000 patients. Unlike the ‘power versus p-value’ representation, those are influenced by sample size. With <strong>bigger sample sizes</strong>:</p>
<ul>
<li><p>As effect size increases, power increases are more steep and p-value decreases more quickly,</p></li>
<li><p>OR values that correspond either to <em>p-values under 0.05</em> or <em>power values over 0.8</em> are closer to 1.</p></li>
</ul>
<pre class="r"><code>or_vs_pvalue &lt;- mydata %&gt;%
   ggplot(
      aes(x=OR, y=pvalue, colour=pvalue)
   ) +
   geom_point() + 
   geom_hline(yintercept=0.05) +
   scale_colour_gradientn(colours = terrain.colors(5)) +
   theme_bw() + theme(legend.position = &quot;none&quot;)

w_vs_pvalue &lt;- mydata %&gt;%
   ggplot(
      aes(x=cohen_w, y=pvalue, colour=pvalue)
   ) +
   geom_point() + 
   geom_hline(yintercept=0.05) +
   scale_colour_gradientn(colours = terrain.colors(5)) +
   theme_bw() + theme(legend.position = &quot;none&quot;)

or_vs_power &lt;- mydata %&gt;%
   ggplot(
      aes(x=OR, y=power, colour=pvalue)
   ) +
   geom_point() + 
   geom_hline(yintercept=0.8) +
   scale_colour_gradientn(colours = terrain.colors(5)) +
   theme_bw() + theme(legend.position = &quot;none&quot;)

w_vs_power &lt;- mydata %&gt;%
   ggplot(
      aes(x=cohen_w, y=power, colour=pvalue)
   ) +
   geom_point() + 
   geom_hline(yintercept=0.8) +
   scale_colour_gradientn(colours = terrain.colors(5)) +
   theme_bw() + theme(legend.position = &quot;none&quot;)

cowplots &lt;- list(or_vs_pvalue, w_vs_pvalue, or_vs_power, w_vs_power) 
mylabels &lt;- letters[1:length(cowplots)]
composed_figure &lt;- cowplot::plot_grid(plotlist = cowplots,
                 labels = mylabels, nrow = 2, align = &quot;h&quot;) 

composed_figure</code></pre>
<p><img src="/post/2020-01-04-playing-with-post-hoc-power-with-r-why-you-shouldn-t-do-it_files/figure-html/plot_output2-1.png" width="1152" />  </p>
</div>
<div id="this-.rmd-source-code" class="section level4">
<h4>This .Rmd source code</h4>
<p>You can download it from <a href="https://github.com/aurora-mareviv/talesofr/blob/master/content/post/2020-01-04-playing-with-post-hoc-power-with-r-why-you-shouldn-t-do-it.Rmd" target="blank">here</a></p>
</div>
</div>
